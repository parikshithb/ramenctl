# ramenctl validate

The validate commands help to troubleshoot disaster recovery problems. They
gathers data from the clusters and detects problems in configuration and the
current status of the clusters or protected applications.

```console
$ ramenctl validate -h
Detect disaster recovery problems

Usage:
  ramenctl validate [command]

Available Commands:
  application Detect problems in disaster recovery protected application
  clusters    Detect problems in disaster recovery clusters

Flags:
  -h, --help            help for validate
  -o, --output string   output directory

Global Flags:
  -c, --config string   configuration file (default "config.yaml")

Use "ramenctl validate [command] --help" for more information about a command.
```

The command supports the following sub-commands:

* [application](#validate-application)
* [clusters](#validate-clusters)

> [!IMPORTANT]
> The validate command requires a configuration file. See [init](docs/init.md) to
> learn how to create one.

## validate application

The validate application command validates a specific DR-protected application
by gathering related namespaces from all clusters, S3 data and inspecting the
gathered resources.

### Looking up applications

To run the validate application command, we need to find the protected
application name and namespace. Run the following command:

```console
$ kubectl get drpc -A --context hub
NAMESPACE   NAME                   AGE   PREFERREDCLUSTER   FAILOVERCLUSTER   DESIREDSTATE   CURRENTSTATE
argocd      appset-deploy-rbd      69m   dr1                dr2               Relocate       Relocated
```

### Validating an application

To validate the application `appset-deploy-rbd` in namespace `argocd` run the
following command:

```console
$ ramenctl validate application --name appset-deploy-rbd --namespace argocd -o out
â­ Using config "config.yaml"
â­ Using report "out"

ðŸ”Ž Validate config ...
   âœ… Config validated

ðŸ”Ž Validate application ...
   âœ… Inspected application
   âœ… Gathered data from cluster "dr2"
   âœ… Gathered data from cluster "dr1"
   âœ… Gathered data from cluster "hub"
   âœ… Inspected S3 profiles
   âœ… Gathered S3 profile "minio-on-dr1"
   âœ… Gathered S3 profile "minio-on-dr2"
   âœ… Application validated

âœ… Validation completed (24 ok, 0 stale, 0 problem)
```

The command gathered related namespaced from all clusters, inspected the
resources, and stored output files in the specified output directory:

```console
$ tree -L1 out
out
â”œâ”€â”€ validate-application.data
â”œâ”€â”€ validate-application.log
â””â”€â”€ validate-application.yaml
```

> [!IMPORTANT]
> When reporting DR related issues, please create an archive with the output
> directory and upload it to the issue tracker.

### The validate-application.yaml

The `validate-application.yaml` report is a machine and human readable
description of the command and the application status.

The most important part of the report is the `applicationStatus`:

```yaml
applicationStatus:
  hub:
    drpc:
      action:
        state: ok âœ…
        value: Relocate
      conditions:
      - state: ok âœ…
        type: Available
      - state: ok âœ…
        type: PeerReady
      - state: ok âœ…
        type: Protected
      deleted:
        state: ok âœ…
      drPolicy: dr-policy
      name: appset-deploy-rbd
      namespace: argocd
      phase:
        state: ok âœ…
        value: Relocated
      progression:
        state: ok âœ…
        value: Completed
  primaryCluster:
    name: dr1
    vrg:
      conditions:
      - state: ok âœ…
        type: DataReady
      - state: ok âœ…
        type: ClusterDataReady
      - state: ok âœ…
        type: ClusterDataProtected
      - state: ok âœ…
        type: KubeObjectsReady
      - state: ok âœ…
        type: NoClusterDataConflict
      deleted:
        state: ok âœ…
      name: appset-deploy-rbd
      namespace: e2e-appset-deploy-rbd
      protectedPVCs:
      - conditions:
        - state: ok âœ…
          type: DataReady
        - state: ok âœ…
          type: ClusterDataProtected
        deleted:
          state: ok âœ…
        name: busybox-pvc
        namespace: e2e-appset-deploy-rbd
        phase:
          state: ok âœ…
          value: Bound
        replication: volrep
      state:
        state: ok âœ…
        value: Primary
  s3:
    profiles:
      state: ok âœ…
      value:
      - gathered:
          state: ok âœ…
          value: true
        name: minio-on-dr1
      - gathered:
          state: ok âœ…
          value: true
        name: minio-on-dr2
  secondaryCluster:
    name: dr2
    vrg:
      conditions:
      - state: ok âœ…
        type: NoClusterDataConflict
      deleted:
        state: ok âœ…
      name: appset-deploy-rbd
      namespace: e2e-appset-deploy-rbd
      state:
        state: ok âœ…
        value: Secondary
```

### The validate-application.data directory

This directory contains all data gathered during validation. The data depend on
the application deployment type. Use the gathered data to investigate the
problems reported in the `validate-application.yaml` report.

```console
$ tree -L3 out/validate-application.data
out/validate-application.data
â”œâ”€â”€ dr1
â”‚Â Â  â”œâ”€â”€ cluster
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ namespaces
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ persistentvolumes
â”‚Â Â  â”‚Â Â  â””â”€â”€ storage.k8s.io
â”‚Â Â  â””â”€â”€ namespaces
â”‚Â Â      â””â”€â”€ e2e-appset-deploy-rbd
â”œâ”€â”€ dr2
â”‚Â Â  â”œâ”€â”€ cluster
â”‚Â Â  â”‚Â Â  â””â”€â”€ namespaces
â”‚Â Â  â””â”€â”€ namespaces
â”‚Â Â      â””â”€â”€ e2e-appset-deploy-rbd
â”œâ”€â”€ hub
â”‚   â”œâ”€â”€ cluster
â”‚   â”‚   â””â”€â”€ namespaces
â”‚   â””â”€â”€ namespaces
â”‚       â””â”€â”€ argocd
â””â”€â”€ s3
    â”œâ”€â”€ minio-on-dr1
    â”‚   â””â”€â”€ e2e-appset-deploy-rbd
    â””â”€â”€ minio-on-dr2
        â””â”€â”€ e2e-appset-deploy-rbd
```

### The validate-application.log

This log includes detailed information that may help to troubleshoot the
validate application command. If the command failed, check the error details in
the log.

## validate clusters

The validate clusters command validates the disaster recovery clusters by
gathering cluster scoped and related ramen resources from all clusters, and
validates that configured S3 endpoints are accessible.

### Validating clusters

To validate the disaster recovery clusters, run the following command:

```console
$ ramenctl validate clusters -o out
â­ Using config "config.yaml"
â­ Using report "out"

ðŸ”Ž Validate config ...
   âœ… Config validated

ðŸ”Ž Validate clusters ...
   âœ… Gathered data from cluster "hub"
   âœ… Gathered data from cluster "dr1"
   âœ… Gathered data from cluster "dr2"
   âœ… Inspected S3 profiles
   âœ… Checked S3 profile "minio-on-dr2"
   âœ… Checked S3 profile "minio-on-dr1"
   âœ… Clusters validated

âœ… Validation completed (42 ok, 0 stale, 0 problem)
```

The command gathered cluster scoped and ramen resources from all clusters,
inspected the resources, and stored output files in the specified output
directory:

```console
$ tree -L1 out
out
â”œâ”€â”€ validate-clusters.data
â”œâ”€â”€ validate-clusters.log
â””â”€â”€ validate-clusters.yaml
```

> [!IMPORTANT]
> When reporting DR related issues, please create an archive with the output
> directory and upload it to the issue tracker.

### The validate-clusters.yaml

The `validate-clusters.yaml` report is a machine and human readable description
of the command and the clusters status.

The most important part of the report is the `clustersStatus`:

```yaml
clustersStatus:
  clusters:
  - name: dr1
    ramen:
      configmap:
        deleted:
          state: ok âœ…
        name: ramen-dr-cluster-operator-config
        namespace: ramen-system
        ramenControllerType:
          state: ok âœ…
          value: dr-cluster
        s3StoreProfiles:
          state: ok âœ…
          value:
          - s3ProfileName: minio-on-dr1
            s3SecretRef:
              state: ok âœ…
              value:
                name: ramen-s3-secret-dr1
                namespace: ramen-system
          - s3ProfileName: minio-on-dr2
            s3SecretRef:
              state: ok âœ…
              value:
                name: ramen-s3-secret-dr2
                namespace: ramen-system
      deployment:
        conditions:
        - state: ok âœ…
          type: Available
        - state: ok âœ…
          type: Progressing
        deleted:
          state: ok âœ…
        name: ramen-dr-cluster-operator
        namespace: ramen-system
        replicas:
          state: ok âœ…
          value: 1
  - name: dr2
    ramen:
      configmap:
        deleted:
          state: ok âœ…
        name: ramen-dr-cluster-operator-config
        namespace: ramen-system
        ramenControllerType:
          state: ok âœ…
          value: dr-cluster
        s3StoreProfiles:
          state: ok âœ…
          value:
          - s3ProfileName: minio-on-dr1
            s3SecretRef:
              state: ok âœ…
              value:
                name: ramen-s3-secret-dr1
                namespace: ramen-system
          - s3ProfileName: minio-on-dr2
            s3SecretRef:
              state: ok âœ…
              value:
                name: ramen-s3-secret-dr2
                namespace: ramen-system
      deployment:
        conditions:
        - state: ok âœ…
          type: Progressing
        - state: ok âœ…
          type: Available
        deleted:
          state: ok âœ…
        name: ramen-dr-cluster-operator
        namespace: ramen-system
        replicas:
          state: ok âœ…
          value: 1
  hub:
    drClusters:
      state: ok âœ…
      value:
      - conditions:
        - state: ok âœ…
          type: Fenced
        - state: ok âœ…
          type: Clean
        - state: ok âœ…
          type: Validated
        name: dr1
        phase: Available
      - conditions:
        - state: ok âœ…
          type: Fenced
        - state: ok âœ…
          type: Clean
        - state: ok âœ…
          type: Validated
        name: dr2
        phase: Available
    drPolicies:
      state: ok âœ…
      value:
      - conditions:
        - state: ok âœ…
          type: Validated
        drClusters:
        - dr1
        - dr2
        name: dr-policy
        schedulingInterval: 1m
    ramen:
      configmap:
        deleted:
          state: ok âœ…
        name: ramen-hub-operator-config
        namespace: ramen-system
        ramenControllerType:
          state: ok âœ…
          value: dr-hub
        s3StoreProfiles:
          state: ok âœ…
          value:
          - s3ProfileName: minio-on-dr1
            s3SecretRef:
              state: ok âœ…
              value:
                name: ramen-s3-secret-dr1
                namespace: ramen-system
          - s3ProfileName: minio-on-dr2
            s3SecretRef:
              state: ok âœ…
              value:
                name: ramen-s3-secret-dr2
                namespace: ramen-system
      deployment:
        conditions:
        - state: ok âœ…
          type: Available
        - state: ok âœ…
          type: Progressing
        deleted:
          state: ok âœ…
        name: ramen-hub-operator
        namespace: ramen-system
        replicas:
          state: ok âœ…
          value: 1
  s3:
    profiles:
      state: ok âœ…
      value:
      - accessible:
          state: ok âœ…
          value: true
        name: minio-on-dr2
      - accessible:
          state: ok âœ…
          value: true
        name: minio-on-dr1
```

### The validate-clusters.data directory

This directory contains all data gathered during validation. Use the gathered
data to investigate the problems reported in the `validate-clusters.yaml` report.

```console
$ tree -L3 out/validate-clusters.data
out/validate-clusters.data
â”œâ”€â”€ dr1
â”‚   â”œâ”€â”€ cluster
â”‚   â”‚   â”œâ”€â”€ apiextensions.k8s.io
â”‚   â”‚   â”œâ”€â”€ apiregistration.k8s.io
â”‚   â”‚   â”œâ”€â”€ cluster.open-cluster-management.io
â”‚   â”‚   â”œâ”€â”€ flowcontrol.apiserver.k8s.io
â”‚   â”‚   â”œâ”€â”€ namespaces
â”‚   â”‚   â”œâ”€â”€ networking.k8s.io
â”‚   â”‚   â”œâ”€â”€ nodes
â”‚   â”‚   â”œâ”€â”€ operator.open-cluster-management.io
â”‚   â”‚   â”œâ”€â”€ operators.coreos.com
â”‚   â”‚   â”œâ”€â”€ persistentvolumes
â”‚   â”‚   â”œâ”€â”€ ramendr.openshift.io
â”‚   â”‚   â”œâ”€â”€ rbac.authorization.k8s.io
â”‚   â”‚   â”œâ”€â”€ replication.storage.openshift.io
â”‚   â”‚   â”œâ”€â”€ scheduling.k8s.io
â”‚   â”‚   â”œâ”€â”€ snapshot.storage.k8s.io
â”‚   â”‚   â”œâ”€â”€ storage.k8s.io
â”‚   â”‚   â”œâ”€â”€ submariner.io
â”‚   â”‚   â””â”€â”€ work.open-cluster-management.io
â”‚   â””â”€â”€ namespaces
â”‚       â””â”€â”€ ramen-system
â”œâ”€â”€ dr2
â”‚   â”œâ”€â”€ cluster
â”‚   â”‚   â”œâ”€â”€ apiextensions.k8s.io
â”‚   â”‚   â”œâ”€â”€ apiregistration.k8s.io
â”‚   â”‚   â”œâ”€â”€ cluster.open-cluster-management.io
â”‚   â”‚   â”œâ”€â”€ flowcontrol.apiserver.k8s.io
â”‚   â”‚   â”œâ”€â”€ namespaces
â”‚   â”‚   â”œâ”€â”€ networking.k8s.io
â”‚   â”‚   â”œâ”€â”€ nodes
â”‚   â”‚   â”œâ”€â”€ operator.open-cluster-management.io
â”‚   â”‚   â”œâ”€â”€ operators.coreos.com
â”‚   â”‚   â”œâ”€â”€ persistentvolumes
â”‚   â”‚   â”œâ”€â”€ ramendr.openshift.io
â”‚   â”‚   â”œâ”€â”€ rbac.authorization.k8s.io
â”‚   â”‚   â”œâ”€â”€ replication.storage.openshift.io
â”‚   â”‚   â”œâ”€â”€ scheduling.k8s.io
â”‚   â”‚   â”œâ”€â”€ snapshot.storage.k8s.io
â”‚   â”‚   â”œâ”€â”€ storage.k8s.io
â”‚   â”‚   â”œâ”€â”€ submariner.io
â”‚   â”‚   â””â”€â”€ work.open-cluster-management.io
â”‚   â””â”€â”€ namespaces
â”‚       â””â”€â”€ ramen-system
â””â”€â”€ hub
    â”œâ”€â”€ cluster
    â”‚   â”œâ”€â”€ addon.open-cluster-management.io
    â”‚   â”œâ”€â”€ admissionregistration.k8s.io
    â”‚   â”œâ”€â”€ apiextensions.k8s.io
    â”‚   â”œâ”€â”€ apiregistration.k8s.io
    â”‚   â”œâ”€â”€ cluster.open-cluster-management.io
    â”‚   â”œâ”€â”€ flowcontrol.apiserver.k8s.io
    â”‚   â”œâ”€â”€ namespaces
    â”‚   â”œâ”€â”€ networking.k8s.io
    â”‚   â”œâ”€â”€ nodes
    â”‚   â”œâ”€â”€ operator.open-cluster-management.io
    â”‚   â”œâ”€â”€ operators.coreos.com
    â”‚   â”œâ”€â”€ ramendr.openshift.io
    â”‚   â”œâ”€â”€ rbac.authorization.k8s.io
    â”‚   â”œâ”€â”€ scheduling.k8s.io
    â”‚   â””â”€â”€ storage.k8s.io
    â””â”€â”€ namespaces
        â””â”€â”€ ramen-system
```

### The validate-clusters.log

This log includes detailed information that may help to troubleshoot the
validate clusters command. If the command failed, check the error details in
the log.
